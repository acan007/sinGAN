# logger options
log_iter: 200                  # How often do you want to log the training stats

# optimization options
n_iter: 2000                   # number of training iterations for scale
batch_size: 1                  # batch size
beta1: 0.5                     # Adam parameter
beta2: 0.999                   # Adam parameter
init: kaiming                  # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0005                     # initial learning rate
g_step: 3                      # generator inner steps
d_step: 3                      # discriminator inner steps
w_recon: 100                   # weight for sample reconstruction loss
w_gp: 0.1                      # weight for gradient penalty of Wasserstein adversarial loss

# model options
sr_factor: 4                   # super resolution factor, s
gen:
  dim: 32                      # number of filters in the bottommost layer
  norm: bn                     # norm
  activ: lrelu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 5                   # number of layers in each generator block
dis:
  dim: 32                      # number of filters in the bottommost layer
  norm: bn                     # normalization layer [none/bn/in/ln]
  activ: lrelu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 5                   # number of layers in each discriminator block

# data options
path_data: Images/mountains3.png               # path of source data
path_sample_save: results/samples              # path of sample saving
path_model_save: results/models                # path of model saving
save_name: SR                                  # prefix for save path